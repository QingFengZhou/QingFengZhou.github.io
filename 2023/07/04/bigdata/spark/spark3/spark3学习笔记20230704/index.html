<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>spark3学习笔记20230704 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Example wordcount SparkLauncher   DataSet Dataset API Common Cube 数据立方     SparkSql Group by 分组 cube用法        Examplewordcount12345&lt;dependency&gt;    &lt;groupId&gt;org.apache.spark&lt;&#x2F;groupId&amp;">
<meta property="og:type" content="article">
<meta property="og:title" content="spark3学习笔记20230704">
<meta property="og:url" content="https://qingfengzhou.github.io/2023/07/04/bigdata/spark/spark3/spark3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020230704/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Example wordcount SparkLauncher   DataSet Dataset API Common Cube 数据立方     SparkSql Group by 分组 cube用法        Examplewordcount12345&lt;dependency&gt;    &lt;groupId&gt;org.apache.spark&lt;&#x2F;groupId&amp;">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-07-04T03:08:56.000Z">
<meta property="article:modified_time" content="2023-07-05T15:59:18.628Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="spark">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://qingfengzhou.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-bigdata/spark/spark3/spark3学习笔记20230704" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/07/04/bigdata/spark/spark3/spark3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020230704/" class="article-date">
  <time class="dt-published" datetime="2023-07-04T03:08:56.000Z" itemprop="datePublished">2023-07-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata-spark-spark3/">bigdata/spark/spark3</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      spark3学习笔记20230704
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <!-- toc -->

<ul>
<li><a href="#example">Example</a><ul>
<li><a href="#wordcount">wordcount</a></li>
<li><a href="#sparklauncher">SparkLauncher</a></li>
</ul>
</li>
<li><a href="#dataset">DataSet</a><ul>
<li><a href="#dataset-api">Dataset API</a><ul>
<li><a href="#common">Common</a></li>
<li><a href="#cube-%E6%95%B0%E6%8D%AE%E7%AB%8B%E6%96%B9">Cube 数据立方</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#sparksql">SparkSql</a><ul>
<li><a href="#group-by-%E5%88%86%E7%BB%84">Group by 分组</a><ul>
<li><a href="#cube%E7%94%A8%E6%B3%95">cube用法</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->

<h2><span id="example">Example</span></h2><h3><span id="wordcount">wordcount</span></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spark-sql_2.12&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.4.1&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.sql.SparkSession</span><br><span class="line"></span><br><span class="line">object DatasetExample &#123;</span><br><span class="line"></span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val spark = SparkSession</span><br><span class="line">      .builder()</span><br><span class="line">      .appName(&quot;Spark SQL basic example&quot;)</span><br><span class="line">      .master(&quot;local&quot;)</span><br><span class="line">      .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    import spark.implicits._</span><br><span class="line"></span><br><span class="line">    val textFile = spark.read.textFile(&quot;file:/Users/**/Desktop/software/spark3/spark-3.4.1-bin-hadoop3/README.md&quot;)</span><br><span class="line"></span><br><span class="line">//    textFile.show()</span><br><span class="line">//    textFile.count()</span><br><span class="line">//    textFile.first()</span><br><span class="line">    //word最多的行有多少个word</span><br><span class="line">//    textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a, b) =&gt; if (a &gt; b) a else b)</span><br><span class="line">    //identity : scala predef预定义的一个函数，返回值等于传入参数</span><br><span class="line">    val wordCounts = textFile</span><br><span class="line">            .flatMap(line =&gt; line.split(&quot; &quot;))</span><br><span class="line">            .groupByKey(identity)</span><br><span class="line">            .count()</span><br><span class="line">            .selectExpr(&quot;key as value&quot;, &quot;`count(1)` as count&quot;)</span><br><span class="line"></span><br><span class="line">    wordCounts.printSchema()</span><br><span class="line">    wordCounts.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /* wordCounts2 等价于 上面的 wordCounts，</span><br><span class="line">       等价于sql中的 select value, count(1) count from tb1 group by value</span><br><span class="line">       等价于mapreduce中的wordcount</span><br><span class="line"></span><br><span class="line">    val wordCounts2 = textFile</span><br><span class="line">      .flatMap(line =&gt; line.split(&quot; &quot;))</span><br><span class="line">      .groupBy(&quot;value&quot;)</span><br><span class="line">      .count()</span><br><span class="line"></span><br><span class="line">    wordCounts2.show()</span><br><span class="line">     */</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3><span id="sparklauncher">SparkLauncher</span></h3><p>java代码里提交spark任务到指定集群，</p>
<p>（官方说法：The <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/launcher/package-summary.html">org.apache.spark.launcher</a> package provides classes for launching Spark jobs as child processes using a simple Java API.）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.launcher.SparkAppHandle;</span><br><span class="line">import org.apache.spark.launcher.SparkLauncher;</span><br><span class="line"></span><br><span class="line">import java.io.File;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line"></span><br><span class="line">public class TestSparkLauncher &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">        HashMap&lt;String, String&gt; envParams = new HashMap&lt;&gt;();</span><br><span class="line">//        envParams.put(&quot;YARN_CONF_DIR&quot;, &quot;/Users/zhouqingfeng/Desktop/software/hadoop-2.7.7&quot;);</span><br><span class="line">//        envParams.put(&quot;HADOOP_CONF_DIR&quot;, &quot;/Users/zhouqingfeng/Desktop/software/hadoop-2.7.7&quot;);</span><br><span class="line">        envParams.put(&quot;SPARK_HOME&quot;, &quot;/Users/zhouqingfeng/Desktop/software/spark-2.4.0-bin-hadoop2.7/&quot;);</span><br><span class="line">        envParams.put(&quot;SPARK_PRINT_LAUNCH_COMMAND&quot;, &quot;1&quot;);</span><br><span class="line">//        envParams.put(&quot;JAVA_HOME&quot;, &quot;/usr/java&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        SparkLauncher launcher = new SparkLauncher(envParams)</span><br><span class="line">                .setAppResource(&quot;/Users/zhouqingfeng/Desktop/software/spark-2.4.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.0.jar&quot;)</span><br><span class="line">                .setMainClass(&quot;org.apache.spark.examples.SparkPi&quot;)</span><br><span class="line">                .setMaster(&quot;local[2]&quot;)</span><br><span class="line">                .setDeployMode(&quot;client&quot;)</span><br><span class="line">                .addAppArgs(&quot;20&quot;);</span><br><span class="line"></span><br><span class="line">        String appName = &quot;sparklancherTest&quot;;</span><br><span class="line">        launcher.setConf(&quot;spark.executor.memory&quot;, &quot;1g&quot;);</span><br><span class="line">        launcher.setAppName( appName );</span><br><span class="line"></span><br><span class="line">//        launcher.addJar(&quot;/Users/zhouqingfeng/Desktop/software/spark-2.4.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.0.jar&quot;);</span><br><span class="line">//        launcher.redirectOutput(new File(&quot;/Users/zhouqingfeng/Desktop/mydirect/data/spark/redir/test1&quot;) );</span><br><span class="line"></span><br><span class="line">        SparkAppHandle sparkHandle = launcher.startApplication();</span><br><span class="line"></span><br><span class="line">        while(!sparkHandle.getState().isFinal()) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(1000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                Thread.currentThread().interrupt();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2><span id="dataset">DataSet</span></h2><p>dataframe是dataset的一种特殊形式，所有元素类型被泛化为row（untyped）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">type DataFrame = Dataset[org.apache.spark.sql.Row]</span><br></pre></td></tr></table></figure>

<h3><span id="dataset-api">Dataset API</span></h3><h4><span id="common">Common</span></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.sql.SparkSession</span><br><span class="line"></span><br><span class="line">object DatasetUsageExample &#123;</span><br><span class="line"></span><br><span class="line">  case class Person(age:Long, name:String)</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val spark = SparkSession</span><br><span class="line">      .builder()</span><br><span class="line">      .appName(&quot;Spark SQL basic example&quot;)</span><br><span class="line">      .master(&quot;local&quot;)</span><br><span class="line">      .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    import spark.implicits._</span><br><span class="line"></span><br><span class="line">    val df  = spark.read.json(&quot;file:/Users/zhouqingfeng/Desktop/software/spark3/spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.json&quot;)</span><br><span class="line"></span><br><span class="line">    val ds1 = df.as[Person]</span><br><span class="line"></span><br><span class="line">    ds1.cache()</span><br><span class="line"></span><br><span class="line">//    ds1.checkpoint()</span><br><span class="line">    ds1.explain(true)</span><br><span class="line"></span><br><span class="line">    val ds2 = ds1.where(&quot;name = &#x27;Andy&#x27;&quot;)</span><br><span class="line">    //hint 提示词</span><br><span class="line">    ds1.join(ds2.hint(&quot;broadcast&quot;))</span><br><span class="line"></span><br><span class="line">    //ds1.repartition($&quot;age&quot;).write.save(&quot;file:/Users/zhouqingfeng/Desktop/software/spark3/spark-3.4.1-bin-hadoop3/examples/src/main/resources/out2/&quot;)</span><br><span class="line"></span><br><span class="line">    //添加一列</span><br><span class="line">    ds1.withColumn(&quot;age1&quot;, $&quot;age&quot; + 1 ).show</span><br><span class="line"></span><br><span class="line">    //重命名</span><br><span class="line">    ds1.select($&quot;name&quot;.as(&quot;name1&quot;))</span><br><span class="line"></span><br><span class="line">    //删除一列</span><br><span class="line">    ds1.withColumn(&quot;age1&quot;, $&quot;age&quot; + 1).drop(&quot;age&quot;)</span><br><span class="line"></span><br><span class="line">    //join</span><br><span class="line">    val ds3 = ds1</span><br><span class="line">    ds1.join(ds3, ds1.col(&quot;age&quot;) === ds3.col(&quot;age&quot;) &amp;&amp; ds1.col(&quot;name&quot;) === ds3.col(&quot;name&quot;), &quot;inner&quot;)</span><br><span class="line">       .show()</span><br><span class="line"></span><br><span class="line">    //sql.functions</span><br><span class="line">    import org.apache.spark.sql.functions._</span><br><span class="line">    ds1.agg( max($&quot;age&quot;) ).show()</span><br><span class="line"></span><br><span class="line">    //statistics for numeric and string columns</span><br><span class="line">    ds1.describe(&quot;age&quot;)</span><br><span class="line">    ds1.summary()</span><br><span class="line"></span><br><span class="line">    // 替换字段中的null为11</span><br><span class="line">    ds1.na.fill(11).show</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4><span id="cube-数据立方">Cube 数据立方</span></h4><p>Cube  + rollup + pivot透视</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.sql.SparkSession</span><br><span class="line"></span><br><span class="line">object DatasetCubeExample &#123;</span><br><span class="line"></span><br><span class="line">  case class Person(age:Long, name:String)</span><br><span class="line"></span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val spark = SparkSession</span><br><span class="line">      .builder()</span><br><span class="line">      .appName(&quot;Spark SQL basic example&quot;)</span><br><span class="line">      .master(&quot;local&quot;)</span><br><span class="line">      .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    import spark.implicits._</span><br><span class="line"></span><br><span class="line">    //sql.functions</span><br><span class="line">    import org.apache.spark.sql.functions._</span><br><span class="line">    val df1 = Seq((&quot;dev&quot;, &quot;m&quot;, 115),(&quot;sale&quot;, &quot;f&quot;, 95), (&quot;sale&quot;, &quot;m&quot;, 85), (&quot;dev&quot;, &quot;f&quot;, 117), (&quot;dev&quot;, &quot;m&quot;, 117)</span><br><span class="line">                 ).toDF(&quot;dept&quot;, &quot;sex&quot;, &quot;salary&quot;)</span><br><span class="line"></span><br><span class="line">    //rollup 分组,  这里等价于 group by 1 (不分组) + group by dept + group by dept, sex,  agg指明分组后的聚合函数</span><br><span class="line">    df1.rollup(&quot;dept&quot;, &quot;sex&quot;).agg(sum(&quot;salary&quot;).as(&quot;salary_sum&quot;)).show(20)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /*</span><br><span class="line">    分组聚合结果如下</span><br><span class="line">    +----+----+----------+</span><br><span class="line">    |dept| sex|salary_sum|</span><br><span class="line">    +----+----+----------+</span><br><span class="line">    |sale|null|       180|</span><br><span class="line">    |sale|   m|        85|</span><br><span class="line">    | dev|   m|       232|</span><br><span class="line">    | dev|null|       349|</span><br><span class="line">    |null|null|       529|</span><br><span class="line">    |sale|   f|        95|</span><br><span class="line">    | dev|   f|       117|</span><br><span class="line">    +----+----+----------+</span><br><span class="line">     */</span><br><span class="line"></span><br><span class="line">    //cube 分组,  表示取dept和sex两个维度，任意维度组合 分组</span><br><span class="line">    // 这里等价于 group by 1 (不分组) + group by dept + group by sex + group by dept, sex</span><br><span class="line">    df1.cube(&quot;dept&quot;, &quot;sex&quot;).agg(&quot;salary&quot; -&gt; &quot;sum&quot;).show(20)</span><br><span class="line"></span><br><span class="line">    /*</span><br><span class="line">    分组聚合结果如下</span><br><span class="line">    +----+----+-----------+</span><br><span class="line">    |dept| sex|sum(salary)|</span><br><span class="line">    +----+----+-----------+</span><br><span class="line">    |sale|null|        180|</span><br><span class="line">    |null|   m|        317|</span><br><span class="line">    |sale|   m|         85|</span><br><span class="line">    | dev|   m|        232|</span><br><span class="line">    | dev|null|        349|</span><br><span class="line">    |null|null|        529|</span><br><span class="line">    |null|   f|        212|</span><br><span class="line">    |sale|   f|         95|</span><br><span class="line">    | dev|   f|        117|</span><br><span class="line">    +----+----+-----------+</span><br><span class="line">     */</span><br><span class="line"></span><br><span class="line">    //分组之后的 数据透视pivot, group by dept分组之后, 以sex为透视列, sex的取值(m\f)作为透视结果表中列的名字</span><br><span class="line">    val df_pivot = df1.groupBy(&quot;dept&quot;)</span><br><span class="line">      .pivot(&quot;sex&quot;, Seq(&quot;m&quot;, &quot;f&quot;))</span><br><span class="line">      .sum(&quot;salary&quot;)</span><br><span class="line">    df_pivot.show()</span><br><span class="line">    /*</span><br><span class="line">    分组之后的透视结果如下, sex</span><br><span class="line">    +----+---+---+</span><br><span class="line">    |dept|  m|  f|</span><br><span class="line">    +----+---+---+</span><br><span class="line">    | dev|232|117|</span><br><span class="line">    |sale| 85| 95|</span><br><span class="line">    +----+---+---+</span><br><span class="line"></span><br><span class="line">    */</span><br><span class="line"></span><br><span class="line">    //数据反透视，数据透视的逆向</span><br><span class="line">    val df_unpivot = df_pivot.unpivot(Array($&quot;dept&quot;), Array($&quot;m&quot;, $&quot;f&quot;), &quot;sex&quot;, &quot;sum&quot;)</span><br><span class="line">    df_unpivot.show()</span><br><span class="line">    /*</span><br><span class="line">    逆向透视结果如下,</span><br><span class="line">    +----+---+---+</span><br><span class="line">    |dept|sex|sum|</span><br><span class="line">    +----+---+---+</span><br><span class="line">    | dev|  m|232|</span><br><span class="line">    | dev|  f|117|</span><br><span class="line">    |sale|  m| 85|</span><br><span class="line">    |sale|  f| 95|</span><br><span class="line">    +----+---+---+</span><br><span class="line"></span><br><span class="line">    */</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>参考资料</strong>：</p>
<p><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html">spark dataset api</a></p>
<p><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/functions$.html">org.apache.spark.sql.functions</a></p>
<p><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/functions$.html">spark中的透视函数</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/36785151">excel数据透视表制作</a></p>
<h2><span id="sparksql">SparkSql</span></h2><h3><span id="group-by-分组">Group by 分组</span></h3><h4><span id="cube用法">cube用法</span></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GROUP BY GROUPING SETS ((city, car_model), (city), (car_model), ())</span><br><span class="line">GROUP BY city, car_model WITH ROLLUP</span><br><span class="line">GROUP BY city, car_model WITH CUBE</span><br><span class="line">GROUP BY CUBE(city, car_model)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE dealer (id INT, city STRING, car_model STRING, quantity INT);</span><br><span class="line">INSERT INTO dealer VALUES</span><br><span class="line">    (100, &#x27;Fremont&#x27;, &#x27;Honda Civic&#x27;, 10),</span><br><span class="line">    (100, &#x27;Fremont&#x27;, &#x27;Honda Accord&#x27;, 15),</span><br><span class="line">    (100, &#x27;Fremont&#x27;, &#x27;Honda CRV&#x27;, 7),</span><br><span class="line">    (200, &#x27;Dublin&#x27;, &#x27;Honda Civic&#x27;, 20),</span><br><span class="line">    (200, &#x27;Dublin&#x27;, &#x27;Honda Accord&#x27;, 10),</span><br><span class="line">    (200, &#x27;Dublin&#x27;, &#x27;Honda CRV&#x27;, 3),</span><br><span class="line">    (300, &#x27;San Jose&#x27;, &#x27;Honda Civic&#x27;, 5),</span><br><span class="line">    (300, &#x27;San Jose&#x27;, &#x27;Honda Accord&#x27;, 8);</span><br><span class="line"></span><br><span class="line">-- Sum of quantity per dealership. Group by `id`.</span><br><span class="line">SELECT id, sum(quantity) FROM dealer GROUP BY id ORDER BY id;</span><br><span class="line">+---+-------------+</span><br><span class="line">| id|sum(quantity)|</span><br><span class="line">+---+-------------+</span><br><span class="line">|100|           32|</span><br><span class="line">|200|           33|</span><br><span class="line">|300|           13|</span><br><span class="line">+---+-------------+</span><br><span class="line"></span><br><span class="line">-- Use column position in GROUP by clause.</span><br><span class="line">SELECT id, sum(quantity) FROM dealer GROUP BY 1 ORDER BY 1;</span><br><span class="line">+---+-------------+</span><br><span class="line">| id|sum(quantity)|</span><br><span class="line">+---+-------------+</span><br><span class="line">|100|           32|</span><br><span class="line">|200|           33|</span><br><span class="line">|300|           13|</span><br><span class="line">+---+-------------+</span><br><span class="line"></span><br><span class="line">-- Multiple aggregations.</span><br><span class="line">-- 1. Sum of quantity per dealership.</span><br><span class="line">-- 2. Max quantity per dealership.</span><br><span class="line">SELECT id, sum(quantity) AS sum, max(quantity) AS max FROM dealer GROUP BY id ORDER BY id;</span><br><span class="line">+---+---+---+</span><br><span class="line">| id|sum|max|</span><br><span class="line">+---+---+---+</span><br><span class="line">|100| 32| 15|</span><br><span class="line">|200| 33| 20|</span><br><span class="line">|300| 13|  8|</span><br><span class="line">+---+---+---+</span><br><span class="line"></span><br><span class="line">-- Count the number of distinct dealer cities per car_model.</span><br><span class="line">SELECT car_model, count(DISTINCT city) AS count FROM dealer GROUP BY car_model;</span><br><span class="line">+------------+-----+</span><br><span class="line">|   car_model|count|</span><br><span class="line">+------------+-----+</span><br><span class="line">| Honda Civic|    3|</span><br><span class="line">|   Honda CRV|    2|</span><br><span class="line">|Honda Accord|    3|</span><br><span class="line">+------------+-----+</span><br><span class="line"></span><br><span class="line">-- Sum of only &#x27;Honda Civic&#x27; and &#x27;Honda CRV&#x27; quantities per dealership.</span><br><span class="line">SELECT id, sum(quantity) FILTER (</span><br><span class="line">            WHERE car_model IN (&#x27;Honda Civic&#x27;, &#x27;Honda CRV&#x27;)</span><br><span class="line">        ) AS `sum(quantity)` FROM dealer</span><br><span class="line">    GROUP BY id ORDER BY id;</span><br><span class="line">+---+-------------+</span><br><span class="line">| id|sum(quantity)|</span><br><span class="line">+---+-------------+</span><br><span class="line">|100|           17|</span><br><span class="line">|200|           23|</span><br><span class="line">|300|            5|</span><br><span class="line">+---+-------------+</span><br><span class="line"></span><br><span class="line">-- Aggregations using multiple sets of grouping columns in a single statement.</span><br><span class="line">-- Following performs aggregations based on four sets of grouping columns.</span><br><span class="line">-- 1. city, car_model</span><br><span class="line">-- 2. city</span><br><span class="line">-- 3. car_model</span><br><span class="line">-- 4. Empty grouping set. Returns quantities for all city and car models.</span><br><span class="line">SELECT city, car_model, sum(quantity) AS sum FROM dealer</span><br><span class="line">    GROUP BY GROUPING SETS ((city, car_model), (city), (car_model), ())</span><br><span class="line">    ORDER BY city;</span><br><span class="line">+---------+------------+---+</span><br><span class="line">|     city|   car_model|sum|</span><br><span class="line">+---------+------------+---+</span><br><span class="line">|     null|        null| 78|</span><br><span class="line">|     null| HondaAccord| 33|</span><br><span class="line">|     null|    HondaCRV| 10|</span><br><span class="line">|     null|  HondaCivic| 35|</span><br><span class="line">|   Dublin|        null| 33|</span><br><span class="line">|   Dublin| HondaAccord| 10|</span><br><span class="line">|   Dublin|    HondaCRV|  3|</span><br><span class="line">|   Dublin|  HondaCivic| 20|</span><br><span class="line">|  Fremont|        null| 32|</span><br><span class="line">|  Fremont| HondaAccord| 15|</span><br><span class="line">|  Fremont|    HondaCRV|  7|</span><br><span class="line">|  Fremont|  HondaCivic| 10|</span><br><span class="line">| San Jose|        null| 13|</span><br><span class="line">| San Jose| HondaAccord|  8|</span><br><span class="line">| San Jose|  HondaCivic|  5|</span><br><span class="line">+---------+------------+---+</span><br><span class="line"></span><br><span class="line">-- Group by processing with `ROLLUP` clause.</span><br><span class="line">-- Equivalent GROUP BY GROUPING SETS ((city, car_model), (city), ())</span><br><span class="line">SELECT city, car_model, sum(quantity) AS sum FROM dealer</span><br><span class="line">    GROUP BY city, car_model WITH ROLLUP</span><br><span class="line">    ORDER BY city, car_model;</span><br><span class="line">+---------+------------+---+</span><br><span class="line">|     city|   car_model|sum|</span><br><span class="line">+---------+------------+---+</span><br><span class="line">|     null|        null| 78|</span><br><span class="line">|   Dublin|        null| 33|</span><br><span class="line">|   Dublin| HondaAccord| 10|</span><br><span class="line">|   Dublin|    HondaCRV|  3|</span><br><span class="line">|   Dublin|  HondaCivic| 20|</span><br><span class="line">|  Fremont|        null| 32|</span><br><span class="line">|  Fremont| HondaAccord| 15|</span><br><span class="line">|  Fremont|    HondaCRV|  7|</span><br><span class="line">|  Fremont|  HondaCivic| 10|</span><br><span class="line">| San Jose|        null| 13|</span><br><span class="line">| San Jose| HondaAccord|  8|</span><br><span class="line">| San Jose|  HondaCivic|  5|</span><br><span class="line">+---------+------------+---+</span><br><span class="line"></span><br><span class="line">-- Group by processing with `CUBE` clause.</span><br><span class="line">-- Equivalent GROUP BY GROUPING SETS ((city, car_model), (city), (car_model), ())</span><br><span class="line">SELECT city, car_model, sum(quantity) AS sum FROM dealer</span><br><span class="line">    GROUP BY city, car_model WITH CUBE</span><br><span class="line">    ORDER BY city, car_model;</span><br><span class="line">+---------+------------+---+</span><br><span class="line">|     city|   car_model|sum|</span><br><span class="line">+---------+------------+---+</span><br><span class="line">|     null|        null| 78|</span><br><span class="line">|     null| HondaAccord| 33|</span><br><span class="line">|     null|    HondaCRV| 10|</span><br><span class="line">|     null|  HondaCivic| 35|</span><br><span class="line">|   Dublin|        null| 33|</span><br><span class="line">|   Dublin| HondaAccord| 10|</span><br><span class="line">|   Dublin|    HondaCRV|  3|</span><br><span class="line">|   Dublin|  HondaCivic| 20|</span><br><span class="line">|  Fremont|        null| 32|</span><br><span class="line">|  Fremont| HondaAccord| 15|</span><br><span class="line">|  Fremont|    HondaCRV|  7|</span><br><span class="line">|  Fremont|  HondaCivic| 10|</span><br><span class="line">| San Jose|        null| 13|</span><br><span class="line">| San Jose| HondaAccord|  8|</span><br><span class="line">| San Jose|  HondaCivic|  5|</span><br><span class="line">+---------+------------+---+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--Prepare data for ignore nulls example</span><br><span class="line">CREATE TABLE person (id INT, name STRING, age INT);</span><br><span class="line">INSERT INTO person VALUES</span><br><span class="line">    (100, &#x27;Mary&#x27;, NULL),</span><br><span class="line">    (200, &#x27;John&#x27;, 30),</span><br><span class="line">    (300, &#x27;Mike&#x27;, 80),</span><br><span class="line">    (400, &#x27;Dan&#x27;, 50);</span><br><span class="line"></span><br><span class="line">--Select the first row in column age</span><br><span class="line">SELECT FIRST(age) FROM person;</span><br><span class="line">+--------------------+</span><br><span class="line">| first(age, false)  |</span><br><span class="line">+--------------------+</span><br><span class="line">| NULL               |</span><br><span class="line">+--------------------+</span><br><span class="line"></span><br><span class="line">--Get the first row in column `age` ignore nulls,last row in column `id` and sum of column `id`.</span><br><span class="line">SELECT FIRST(age IGNORE NULLS), LAST(id), SUM(id) FROM person;</span><br><span class="line">+-------------------+------------------+----------+</span><br><span class="line">| first(age, true)  | last(id, false)  | sum(id)  |</span><br><span class="line">+-------------------+------------------+----------+</span><br><span class="line">| 30                | 400              | 1000     |</span><br><span class="line">+-------------------+------------------+----------+</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://qingfengzhou.github.io/2023/07/04/bigdata/spark/spark3/spark3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020230704/" data-id="cljo12rbr0000k99a2y8w8wtx" data-title="spark3学习笔记20230704" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/" rel="tag">spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/07/05/bigdata/spark/sparksql/kyuubi/kyuubi_simple_usage/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          kyuubi_simple_usage
        
      </div>
    </a>
  
  
    <a href="/2023/07/04/bigdata/hadoop/hadoop_env/hadoop%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">hadoop本地环境搭建</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/bigdata-hadoop-hadoop-env/">bigdata/hadoop/hadoop_env</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/bigdata-nosql-hbase/">bigdata/nosql/hbase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/bigdata-spark/">bigdata/spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/bigdata-spark-spark3/">bigdata/spark/spark3</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/bigdata-spark-sparksql-kyuubi/">bigdata/spark/sparksql/kyuubi</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/bigdate-spark-spark-env/">bigdate/spark/spark_env</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/life-daily/">life/daily</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/life-thought/">life/thought</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/system-linux-ansible/">system/linux/ansible</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/system-linux-command/">system/linux/command</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/system-linux-host-monitor/">system/linux/host/monitor</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/system-linux-prometheus/">system/linux/prometheus</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tools-draw-%E5%9C%A8%E7%BA%BF%E7%94%BB%E5%9B%BE/">tools/draw/在线画图</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tools-github-hexo/">tools/github/hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tools-java-maven/">tools/java/maven</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/" rel="tag">hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/" rel="tag">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tools/" rel="tag">tools</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/hadoop/" style="font-size: 10px;">hadoop</a> <a href="/tags/spark/" style="font-size: 20px;">spark</a> <a href="/tags/tools/" style="font-size: 10px;">tools</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/07/05/bigdata/spark/sparksql/kyuubi/kyuubi_simple_usage/">kyuubi_simple_usage</a>
          </li>
        
          <li>
            <a href="/2023/07/04/bigdata/spark/spark3/spark3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020230704/">spark3学习笔记20230704</a>
          </li>
        
          <li>
            <a href="/2023/07/04/bigdata/hadoop/hadoop_env/hadoop%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">hadoop本地环境搭建</a>
          </li>
        
          <li>
            <a href="/2023/07/04/bigdata/spark/spark_env/spark%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">spark环境搭建</a>
          </li>
        
          <li>
            <a href="/2023/07/04/tools/draw/%E5%9C%A8%E7%BA%BF%E7%94%BB%E5%9B%BE/processon/">processon</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>